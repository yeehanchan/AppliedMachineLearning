{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['normalize']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import rlcompleter, readline\n",
    "readline.parse_and_bind('tab: complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = np.genfromtxt('label.txt')\n",
    "test_label = np.asarray([1]*300+[0]*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vectors = np.genfromtxt('train_feature_vectors.txt')\n",
    "test_vectors = np.genfromtxt('test_feature_vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((597, 4361), (597,))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are samples in testing set that doesn't contain any words in dictionary\n",
    "#which means the feature_vectors are empty.\n",
    "index = [i for i in range(test_vectors.shape[0]) if np.sum(test_vectors[i]) == 0]\n",
    "clean_test_vectors = np.delete(test_vectors,index,0)\n",
    "clean_test_label = np.delete(test_label,index,0)\n",
    "clean_test_vectors.shape,clean_test_label.shape\n",
    "#after cleaning, 597 testing sample remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597,)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dic = np.genfromtxt('train_dic.txt')\n",
    "test_dic = np.genfromtxt('test_dic.txt')\n",
    "clean_test_dic = np.delete(test_dic,index,0)\n",
    "clean_test_dic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighting strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I tried to nomalize the term-frequency vectors and apply the data into k-means. The performance is not desirable.\n",
    "#I found that many fecture vectors have same distances with each cluster centriods.\n",
    "#I guess that's because using frequency of words can't well differentiate each feacture vectors.\n",
    "#therefore I apply tf-idf strategy to weighting the words.\n",
    "#reference resource: http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/\n",
    "def tf_idf(train_vectors):\n",
    "    tf_idf_train = np.zeros_like(train_vectors)\n",
    "    for i in range(train_vectors.shape[1]):\n",
    "        tf_idf_train[:,i] = np.log(len(train_vectors)/1+np.count_nonzero(train_vectors[:,i])) * train_vectors[:,i]\n",
    "    return tf_idf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf_train = tf_idf(train_vectors)\n",
    "tf_idf_test = tf_idf(clean_test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Normalization After Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "#there are many zero elements in matrix. So if there is words with really high frequencies, that might account to bias.\n",
    "#to reduce the influence of high frequency words.\n",
    "def normalization(train):\n",
    "    train = np.asarray(train)\n",
    "    s_train = []\n",
    "    for i in range(train.shape[0]):\n",
    "        s_train.append(train[i]/np.sqrt(np.sum((train[i])**2)))\n",
    "    return np.asarray(s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize_train = normalization(tf_idf_train)\n",
    "normalize_test = normalization(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.70994625327525807, 0.704255860792385]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in normalize_train[1] if i != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k-means implementation\n",
    "from scipy.spatial import distance\n",
    "def k_means(train,threshold):\n",
    "    #initial centroid\n",
    "    new_m1 = train[np.random.randint(len(train))]\n",
    "    new_m2 = train[np.random.randint(len(train))]\n",
    "    diff = 1000\n",
    "#keep interation until the different between new centroid and old centriod go under the treshold\n",
    "    while(diff > threshold):\n",
    "        c1, c2= [],[]\n",
    "        c1_label,c2_label = [],[]\n",
    "        m1,m2 = new_m1,new_m2\n",
    "        print np.sum(m1),np.sum(m2)\n",
    "        for i,line in enumerate(train):\n",
    "#            print np.sum(line)\n",
    "            dis1 = np.sqrt(sum((line - m1) ** 2))\n",
    "            dis2 = np.sqrt(sum((line - m2) ** 2))\n",
    "#            print \"dis:\",dis1,dis2\n",
    "            #assign each sample to nearest centroid\n",
    "            if(dis1 > dis2):\n",
    "                c2.append(line)\n",
    "                c2_label.append(label[i]);\n",
    "            if(dis1 < dis2):\n",
    "                c1.append(line)\n",
    "                c1_label.append(label[i]);\n",
    "            if(dis1 == dis2):\n",
    "                x = np.random.randint(2);\n",
    "                if(x == 0):\n",
    "                    c1.append(line)\n",
    "                    c1_label.append(label[i]);\n",
    "                if(x == 1):\n",
    "                    c2.append(line) \n",
    "                    c2_label.append(label[i]);\n",
    "        #adjust centroid\n",
    "        new_m1 = np.mean(np.asarray(c1),axis = 0)\n",
    "        new_m2 = np.mean(np.asarray(c2),axis = 0)\n",
    "        print \"new\",np.sum(new_m1),np.sum(new_m2)\n",
    "        #compute the difference between new centroids and old centroids\n",
    "        diff = (np.sqrt(sum((new_m1 - m1) ** 2)) + np.sqrt(sum((new_m2 - m2) ** 2)))/2\n",
    "        print \"diff\",diff\n",
    "    return new_m1,new_m2,c1,c2,c1_label,c2_label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35888869103 2.64574141828\n",
      "new 2.64922110891 2.2714863034\n",
      "diff 0.978722185343\n",
      "2.64922110891 2.2714863034\n",
      "new 2.88776806493 2.29631920676\n",
      "diff 0.0897457062813\n",
      "[ 0.          0.          0.         ...,  0.          0.          0.00141879] [ 0.00016928  0.00023969  0.00027689 ...,  0.00019568  0.00021392\n",
      "  0.00061465]\n"
     ]
    }
   ],
   "source": [
    "m1,m2,c1,c2,c1_labe1,c2_label = k_means(normalize_train,0.5)\n",
    "print m1,m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vote(c):\n",
    "    count0 = len([i for i in c if i == 0.0])\n",
    "    count1 = len([i for i in c if i == 1.0])\n",
    "#    print count0,count1\n",
    "    if(count0 > count1):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_c1 = vote(c1_label)\n",
    "vote_c2 = vote(c2_label)\n",
    "len(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_c1,vote_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#evaluate performance of k-menas\n",
    "def evaluation(c1_label,vote_c1,c2_label,vote_c2):\n",
    "    ratio1 = len([i for i in c1_label if i == vote_c1])/float(len(c1_label))\n",
    "    ratio2 = len([i for i in c2_label if i == vote_c2])/float(len(c2_label))\n",
    "    print \"cluster 1 score:\",ratio1,\"cluster2 score:\",ratio2\n",
    "    ratio = (len([i for i in c1_label if i == vote_c1])+len([i for i in c2_label if i == vote_c2]))/float((len(c1_label)+len(c2_label)))\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1 score: 0.494086021505 cluster2 score: 0.52037037037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(c1_labe1,vote_c1,c2_label,vote_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788944723618\n",
      "[[232  65]\n",
      " [ 61 239]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATcAAAEKCAYAAAB3xhJBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLTm5mVktObmZWS39P5ojjeTtrywrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104e81ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(normalize_train,train_label)\n",
    "#report accuracy of logistic regression\n",
    "pred = clf.predict(normalize_test)\n",
    "accuracy = clf.score(normalize_test,clean_test_label)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(clean_test_label,pred)\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.array([0,1])\n",
    "plt.xticks(tick_marks, [0,1])\n",
    "plt.yticks(tick_marks, [0,1])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print accuracy\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cool', 'liked', 'interesting', 'comfortable', 'definitely', 'recommend', 'delicious', 'fine', 'fantastic', 'beautiful', 'amazing', 'loved', 'wonderful', 'well', 'good', 'nice', 'best', 'excellent', 'love', 'great']\n"
     ]
    }
   ],
   "source": [
    "dic = np.genfromtxt('dic.txt',dtype='str')\n",
    "maxs = sorted(clf.coef_[0])[len(clf.coef_)-21:]\n",
    "#print max_5\n",
    "keywords = []\n",
    "for each in maxs:\n",
    "    index = [i for i in range(clf.coef_.shape[1]) if clf.coef_[0][i] == each]\n",
    "    keywords.extend(dic[index])\n",
    "print keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
