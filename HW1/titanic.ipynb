{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import rlcompleter, readline\n",
    "readline.parse_and_bind('tab: complete')\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  1.  3.  1.  3.  3.  1.  3.  3.  2.  3.  1.  3.  3.  3.  2.  3.  2.\n",
      "  3.  3.  2.  2.  3.  1.  3.  3.  3.  1.  3.  3.  1.  1.  3.  2.  1.  1.\n",
      "  3.  3.  3.  3.  3.  2.  3.  2.  3.  3.  3.  3.  3.  3.  3.  3.  1.  2.\n",
      "  1.  1.  2.  3.  2.  3.  3.  1.  1.  3.  1.  3.  2.  3.  3.  3.  2.  3.\n",
      "  2.  3.  3.  3.  3.  3.  2.  3.  3.  3.  3.  1.  2.  3.  3.  3.  1.  3.\n",
      "  3.  3.  1.  3.  3.  3.  1.  1.  2.  2.  3.  3.  1.  3.  3.  3.  3.  3.\n",
      "  3.  3.  1.  3.  3.  3.  3.  3.  3.  2.  1.  3.  2.  3.  2.  2.  1.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  1.  1.  3.  1.  3.  3.  3.  3.\n",
      "  2.  2.  3.  3.  2.  2.  2.  1.  3.  3.  3.  1.  3.  3.  3.  3.  3.  2.\n",
      "  3.  3.  3.  3.  1.  3.  1.  3.  1.  3.  3.  3.  1.  3.  3.  1.  2.  3.\n",
      "  3.  2.  3.  2.  3.  1.  3.  1.  3.  3.  2.  2.  3.  2.  1.  1.  3.  3.\n",
      "  3.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  1.  3.  2.  3.  2.  3.  1.\n",
      "  3.  2.  1.  2.  3.  2.  3.  3.  1.  3.  2.  3.  2.  3.  1.  3.  2.  3.\n",
      "  2.  3.  2.  2.  2.  2.  3.  3.  2.  3.  3.  1.  3.  2.  1.  2.  3.  3.\n",
      "  1.  3.  3.  3.  1.  1.  1.  2.  3.  3.  1.  1.  3.  2.  3.  3.  1.  1.\n",
      "  1.  3.  2.  1.  3.  1.  3.  2.  3.  3.  3.  3.  3.  3.  1.  3.  3.  3.\n",
      "  2.  3.  1.  1.  2.  3.  3.  1.  3.  1.  1.  1.  3.  3.  3.  2.  3.  1.\n",
      "  1.  1.  2.  1.  1.  1.  2.  3.  2.  3.  2.  2.  1.  1.  3.  3.  2.  2.\n",
      "  3.  1.  3.  2.  3.  1.  3.  1.  1.  3.  1.  3.  1.  1.  3.  1.  2.  1.\n",
      "  2.  2.  2.  2.  2.  3.  3.  3.  3.  1.  3.  3.  3.  3.  1.  2.  3.  3.\n",
      "  3.  2.  3.  3.  3.  3.  1.  3.  3.  1.  1.  3.  3.  1.  3.  1.  3.  1.\n",
      "  3.  3.  1.  3.  3.  1.  3.  2.  3.  2.  3.  2.  1.  3.  3.  1.  3.  3.\n",
      "  3.  2.  2.  2.  3.  3.  3.  3.  3.  2.  3.  2.  3.  3.  3.  3.  1.  2.\n",
      "  3.  3.  2.  2.  2.  3.  3.  3.  3.  3.  3.  3.  2.  2.  3.  3.  1.  3.\n",
      "  2.  3.  1.  1.  3.  2.  1.  2.  2.  3.  3.  2.  3.  1.  2.  1.  3.  1.\n",
      "  2.  3.  1.  1.  3.  3.  1.  1.  2.  3.  1.  3.  1.  2.  3.  3.  2.  1.\n",
      "  3.  3.  3.  3.  2.  2.  3.  1.  2.  3.  3.  3.  3.  2.  3.  3.  1.  3.\n",
      "  1.  1.  3.  3.  3.  3.  1.  1.  3.  3.  1.  3.  1.  3.  3.  3.  3.  3.\n",
      "  1.  1.  2.  1.  3.  3.  3.  3.  1.  1.  3.  1.  2.  3.  2.  3.  1.  3.\n",
      "  3.  1.  3.  3.  2.  1.  3.  2.  2.  3.  3.  3.  3.  2.  1.  1.  3.  1.\n",
      "  1.  3.  3.  2.  1.  1.  2.  2.  3.  2.  1.  2.  3.  3.  3.  1.  1.  1.\n",
      "  1.  3.  3.  3.  2.  3.  3.  3.  3.  3.  3.  3.  2.  1.  1.  3.  3.  3.\n",
      "  2.  1.  3.  3.  2.  1.  2.  1.  3.  1.  2.  1.  3.  3.  3.  1.  3.  3.\n",
      "  2.  3.  2.  3.  3.  1.  2.  3.  1.  3.  1.  3.  3.  1.  2.  1.  3.  3.\n",
      "  3.  3.  3.  2.  3.  3.  2.  2.  3.  1.  3.  3.  3.  1.  2.  1.  3.  3.\n",
      "  1.  3.  1.  1.  3.  2.  3.  2.  3.  3.  3.  1.  3.  3.  3.  1.  3.  1.\n",
      "  3.  3.  3.  2.  3.  3.  3.  2.  3.  3.  2.  1.  1.  3.  1.  3.  3.  2.\n",
      "  2.  3.  3.  1.  2.  1.  2.  2.  2.  3.  3.  3.  3.  1.  3.  1.  3.  3.\n",
      "  2.  2.  3.  3.  3.  1.  1.  3.  3.  3.  1.  2.  3.  3.  1.  3.  1.  1.\n",
      "  3.  3.  3.  2.  2.  1.  1.  3.  1.  1.  1.  3.  2.  3.  1.  2.  3.  3.\n",
      "  2.  3.  2.  2.  1.  3.  2.  3.  2.  3.  1.  3.  2.  2.  2.  3.  3.  1.\n",
      "  3.  3.  1.  1.  1.  3.  3.  1.  3.  2.  1.  3.  2.  3.  3.  3.  2.  2.\n",
      "  3.  2.  3.  1.  3.  3.  3.  1.  3.  1.  1.  3.  3.  3.  3.  3.  2.  3.\n",
      "  2.  3.  3.  3.  3.  1.  3.  1.  1.  3.  3.  3.  3.  3.  3.  1.  3.  2.\n",
      "  3.  1.  3.  2.  1.  3.  3.  3.  2.  2.  1.  3.  3.  3.  1.  3.  2.  1.\n",
      "  3.  3.  2.  3.  3.  1.  3.  2.  3.  3.  1.  3.  1.  3.  3.  3.  3.  2.\n",
      "  3.  1.  3.  2.  3.  3.  3.  1.  3.  3.  3.  1.  3.  2.  1.  3.  3.  3.\n",
      "  3.  3.  2.  1.  3.  3.  3.  1.  2.  3.  1.  1.  3.  3.  3.  2.  1.  3.\n",
      "  2.  2.  2.  1.  3.  3.  3.  1.  1.  3.  2.  3.  3.  3.  3.  1.  2.  3.\n",
      "  3.  2.  3.  3.  2.  1.  3.  1.  3.]\n"
     ]
    }
   ],
   "source": [
    "from sets import Set\n",
    "from sklearn import preprocessing\n",
    "with open(\"Desktop/MordernAnalytics/assignment1/titanic_train.csv\") as csvfile:\n",
    "    txt = csv.reader(csvfile,delimiter=\",\")\n",
    "    data = []\n",
    "    for each in txt:\n",
    "        if(len(each) > 0):\n",
    "            data.append(each)\n",
    "#            print(each)\n",
    "train = np.asarray(data[1:])\n",
    "train = np.delete(train,(0,3,8,9,10,11),axis=1)\n",
    "le.fit(train[:,2])\n",
    "train[:,2] = le.transform(train[:,2])\n",
    "age_group = []\n",
    "for each in train[:,3]:\n",
    "    if(each < '15'):\n",
    "         age_group.append(0)\n",
    "    elif((each >='15' and each <= '50') or each == \" \"):\n",
    "         age_group.append(1)\n",
    "    else:\n",
    "         age_group.append(2)\n",
    "train[:,3] = np.asarray(age_group)\n",
    "train = train.astype(np.float)\n",
    "print(train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  2.  3.  3.  3.  3.  2.  3.  3.  3.  1.  1.  2.  1.  2.  2.  3.\n",
      "  3.  3.  1.  3.  1.  1.  1.  3.  1.  3.  1.  3.  2.  2.  3.  3.  1.  3.\n",
      "  3.  3.  3.  3.  3.  1.  3.  2.  1.  3.  1.  3.  1.  3.  1.  2.  2.  1.\n",
      "  2.  3.  3.  3.  3.  1.  3.  2.  3.  3.  1.  2.  3.  1.  1.  1.  3.  3.\n",
      "  3.  1.  1.  1.  3.  1.  2.  3.  3.  1.  1.  3.  2.  3.  3.  3.  3.  2.\n",
      "  3.  3.  1.  3.  1.  3.  1.  3.  3.  3.  1.  2.  3.  3.  3.  3.  3.  3.\n",
      "  3.  2.  2.  3.  1.  3.  1.  3.  3.  3.  1.  2.  2.  3.  1.  3.  3.  3.\n",
      "  3.  3.  2.  3.  3.  1.  3.  3.  3.  3.  3.  2.  3.  3.  3.  1.  1.  2.\n",
      "  1.  3.  1.  3.  1.  2.  1.  3.  3.  3.  3.  3.  1.  3.  1.  3.  3.  3.\n",
      "  2.  3.  2.  3.  1.  3.  1.  3.  3.  3.  3.  3.  3.  2.  2.  1.  2.  1.\n",
      "  2.  1.  1.  3.  1.  2.  2.  3.  3.  2.  2.  1.  3.  2.  2.  3.  1.  3.\n",
      "  2.  3.  3.  3.  1.  2.  2.  1.  3.  2.  1.  3.  3.  3.  2.  2.  3.  1.\n",
      "  3.  1.  1.  3.  2.  3.  2.  3.  1.  3.  3.  3.  3.  2.  2.  1.  3.  3.\n",
      "  1.  3.  1.  3.  2.  1.  1.  2.  1.  3.  3.  1.  2.  2.  2.  3.  2.  3.\n",
      "  1.  3.  3.  3.  3.  3.  2.  3.  3.  3.  2.  3.  2.  3.  1.  3.  3.  3.\n",
      "  1.  3.  1.  3.  3.  2.  2.  2.  2.  2.  3.  3.  3.  3.  3.  3.  3.  1.\n",
      "  3.  3.  1.  3.  3.  1.  3.  3.  2.  3.  1.  3.  3.  2.  2.  3.  3.  1.\n",
      "  1.  3.  1.  3.  3.  3.  3.  3.  1.  3.  1.  2.  3.  2.  3.  3.  2.  1.\n",
      "  1.  3.  2.  1.  2.  2.  2.  1.  3.  3.  3.  1.  2.  3.  2.  3.  2.  3.\n",
      "  3.  1.  3.  3.  2.  3.  2.  2.  1.  2.  2.  2.  3.  1.  1.  3.  3.  3.\n",
      "  3.  2.  2.  3.  1.  3.  3.  3.  1.  2.  2.  1.  1.  2.  1.  1.  3.  2.\n",
      "  1.  3.  3.  3.  3.  3.  2.  2.  3.  2.  3.  3.  1.  1.  3.  2.  3.  1.\n",
      "  3.  1.  3.  3.  1.  2.  1.  1.  1.  2.  2.  1.  3.  3.  3.  1.  3.  3.\n",
      "  1.  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "with open(\"Desktop/MordernAnalytics/assignment1/titanic_test.csv\") as csvfile:\n",
    "    txt = csv.reader(csvfile,delimiter=\",\")\n",
    "    data_1 = []\n",
    "    for each in txt:\n",
    "        if(len(each) > 0):\n",
    "            data_1.append(each)\n",
    "data_1 = np.asarray(data_1[1:])\n",
    "test = np.delete(data_1,(0,2,7,8,9,10),axis=1)\n",
    "le.fit(test[:,1])\n",
    "test[:,1] = le.transform(test[:,1])\n",
    "age_group = []\n",
    "for each in test[:,2]:\n",
    "    if(each < '15'):\n",
    "         age_group.append(0)\n",
    "    elif((each >='15' and each <= '50') or each == \" \"):\n",
    "         age_group.append(1)\n",
    "    else:\n",
    "         age_group.append(2)\n",
    "\n",
    "test[:,2] = np.asarray(age_group)\n",
    "test = test.astype(np.float)\n",
    "print(test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(train[:,1:],train[:,0])\n",
    "predict = logistic.predict(test).astype(int)\n",
    "print(predict)\n",
    "#logistic.score(numeric_train[0:300,1:],numeric_train[0:300,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = data_1[:,0]\n",
    "#print(p)\n",
    "import csv\n",
    "with open(\"output.csv\", \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['PassengerId','Survived'])\n",
    "    for i in range(0,len(predict)):\n",
    "        writer.writerow([p[i],predict[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
